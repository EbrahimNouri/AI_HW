سوال ۱: تفاوت Correlation و Covariance چیست؟

Covariance میزان تغییر همزمان دو متغیر را نشان می‌دهد. اگر مثبت باشد یعنی با افزایش یکی، دیگری هم افزایش می‌یابد و اگر منفی باشد یعنی یکی افزایش و دیگری کاهش می‌یابد. مقدار کوواریانس به مقیاس داده‌ها وابسته است و تفسیر عددی مستقیمی ندارد.

Correlation نسخه نرمال‌شده‌ی کوواریانس است که مقدار آن همیشه بین -1 و 1 قرار دارد. این معیار شدت و جهت رابطه خطی را نشان می‌دهد و مستقل از مقیاس داده‌هاست، بنابراین تفسیرپذیرتر از کوواریانس است.

سوال ۲: تفاوت Correlation و Dependency چیست؟

Correlation فقط وابستگی خطی بین متغیرها را اندازه‌گیری می‌کند. اگر رابطه غیرخطی باشد، ممکن است همبستگی صفر باشد ولی وابستگی وجود داشته باشد.

Dependency مفهوم کلی‌تری است و هر نوع وابستگی (خطی، غیرخطی، آماری یا علّی) را شامل می‌شود. بنابراین همبستگی صفر الزاماً به معنی مستقل بودن متغیرها نیست.

سوال ۳: تفاوت Regression و Classification چیست؟

در Regression خروجی مدل یک مقدار پیوسته عددی است (مثل قیمت خانه یا دما).

در Classification خروجی مدل یک برچسب گسسته یا کلاس است (مثل بیمار/سالم یا اسپم/غیراسپم).

به‌طور خلاصه: Regression پیش‌بینی عدد، Classification پیش‌بینی دسته است.

سوال ۴: اثر نویز بر Bias-Variance چیست؟

نویز ذاتی داده باعث افزایش Variance می‌شود، زیرا مدل تلاش می‌کند تغییرات تصادفی را نیز یاد بگیرد.
نویز معمولاً Bias را تغییر نمی‌دهد، چون بایاس به فرضیات مدل وابسته است نه به کیفیت داده.
در داده‌های پرنویز، حتی بهترین مدل هم خطای غیرقابل کاهش خواهد داشت.

سوال ۵: عدم قطعیت داده و عدم قطعیت مدل چیست؟ عدم قطعیت مدل متاثر از چیست؟

عدم قطعیت داده (Data Uncertainty) ناشی از نویز، خطای اندازه‌گیری یا تصادفی بودن فرآیند تولید داده است و کاهش‌ناپذیر است.

عدم قطعیت مدل (Model Uncertainty) ناشی از محدودیت داده آموزشی، انتخاب مدل یا پارامترهاست و با داده بیشتر یا مدل بهتر قابل کاهش است.

عدم قطعیت مدل به عواملی مثل حجم داده، پیچیدگی مدل و روش آموزش وابسته است.

سوال ۶: تفاوت عدم قطعیت و High Dimension چیست؟ چه زمانی مرتبط‌اند و چه زمانی نیستند؟

High Dimension به تعداد زیاد ویژگی‌ها اشاره دارد.
عدم قطعیت به میزان اطمینان مدل در پیش‌بینی مربوط است.

در داده‌های با ابعاد بالا و نمونه کم، عدم قطعیت افزایش می‌یابد (Curse of Dimensionality).
اما اگر داده کافی وجود داشته باشد، بعد بالا الزاماً باعث عدم قطعیت نمی‌شود.

سوال ۷: تفاوت نویز سفید و نویز رنگی چیست؟

نویز سفید دارای توان یکنواخت در تمام فرکانس‌هاست و نمونه‌ها مستقل از هم هستند.

نویز رنگی توان غیر یکنواخت دارد (مثل نویز صورتی یا قهوه‌ای) و بین نمونه‌ها همبستگی زمانی وجود دارد.

سوال ۸: تفاوت Noise و Outlier چیست؟

Noise نوسانات تصادفی کوچک و گسترده در کل داده است.

Outlier نقاطی خاص و نادر هستند که به‌طور قابل‌توجهی از الگوی کلی داده فاصله دارند.

نویز پراکنده است، ولی outlier مشخص و جداافتاده است.

سوال ۹: تفاوت Noise و Anomaly چیست؟

Noise تصادفی، بدون الگوی مشخص و معمولاً کم‌اثر است.

Anomaly رفتار غیرعادی، ساختاریافته و معنادار است که می‌تواند نشان‌دهنده یک رویداد مهم یا خطا باشد.

نویز معمولاً نادیده گرفته می‌شود، ولی anomaly ارزش تحلیل دارد.

سوال ۱۰: تفاوت Outlier و Anomaly چیست؟

Outlier صرفاً از نظر آماری دور از سایر نقاط است.

Anomaly علاوه بر فاصله آماری، از نظر مفهومی نیز غیرعادی و مهم است.

هر anomaly می‌تواند outlier باشد، اما هر outlier الزاماً anomaly نیست.


=====================

Double-click to edit this empty Markdown cell

1️⃣ Bias کم، خطا کم

مدل ساده یا پیچیده ولی خوب fit کرده.

هم روی train و هم روی test خطا کم هست.

وضعیت: مدل عالی، نه underfit و نه overfit.

مثال: Linear Regression خوب روی داده‌های خطی.

2️⃣ Bias کم، خطا زیاد

مدل پیچیده که روی train خیلی خوبه ولی روی test ضعیفه.

Overfitting: مدل جزئیات نویز train رو هم یاد گرفته.

R² روی train بالا، روی test پایین.

راه حل: Regularization (Ridge/Lasso)، کاهش پیچیدگی مدل، افزایش داده.

3️⃣ Bias زیاد، خطا کم

این حالت خیلی نادره، معمولاً وقتی داده‌ها خیلی نزدیک صفر یا بدون تغییر هستند اتفاق میفته.

مدل ساده است، خطا عددی کم چون مقادیر هدف کوچک هستند، ولی مدل هیچ رابطه‌ای یاد نگرفته → R² پایین.

مثال: مدل همیشه میانگین y رو پیش‌بینی می‌کنه.

وضعیت: underfitting ولی خطا ظاهراً کم است.

4️⃣ Bias زیاد، خطا زیاد

مدل خیلی ساده و ضعیف برای داده‌های پیچیده.

نه روی train و نه روی test خوب کار نمی‌کنه.

Underfitting شدید: مدل نمی‌تونه رابطه‌ها رو یاد بگیره.

مثال: Linear Regression ساده روی داده‌های غیرخطی شدید.

===============



سوال ۱: چطور دقت مدل را برای این کار اندازه‌گیری می‌کنید؟
پاسخ: چون داده‌ها نامتوازن هستند (بیماران پذیرش شده کم‌ترند)، فقط دقت (Accuracy) کافی نیست. باید:
1. F1-Score: میانگین توازن‌دار Precision و Recall
2. ROC-AUC: توانایی مدل در تشخیص کلاس‌ها
3. Confusion Matrix: تعداد واقعی TP, TN, FP, FN
4. Precision و Recall جداگانه:
    * Precision مهم است که بیماران سالم را اشتباه پرریسک تشخیص ندهیم
    * Recall مهم است که بیماران پرریسک واقعی را شناسایی کنیم

سوال ۲: چطور بایاس (تعصب) مدل را بررسی می‌کنید؟
پاسخ:
1. بررسی عملکرد در گروه‌های مختلف:
    * عملکرد مدل را در گروه‌های سنی، جنسیتی، نژادی مختلف مقایسه کنیم
2. مقایسه معیارها:
    * آیا Recall و Precision برای همه گروه‌ها یکسان است؟
3. تحلیل ویژگی‌های حساس:
    * آیا مدل بیش‌ازحد به ویژگی‌های حساس (مثل نژاد) وابسته است؟
4. استفاده از معیارهای عدالت:
    * Demographic Parity, Equal Opportunity, Equalized Odds

سوال ۳: اثر داده‌های نامتوازن روی عملکرد مدل چیست؟ چطور این چالش را حل می‌کنید؟
پاسخ: اثرات:
* مدل به کلاس اکثریت (عدم پذیرش) تمایل پیدا می‌کند
* دقت بالا اما Recall برای کلاس اقلیت (پذیرش) پایین است
راه‌حل‌ها:
1. در سطح داده:
    * Oversampling (مثل SMOTE): تولید نمونه‌های مصنوعی از کلاس اقلیت
    * Undersampling: کاهش نمونه‌های کلاس اکثریت
2. در سطح الگوریتم:
    * Class weighting: وزن بیشتر به کلاس اقلیت بدهیم
    * استفاده از الگوریتم‌هایی مثل XGBoost که خودش imbalance را مدیریت می‌کند
3. در سطح ارزیابی:
    * استفاده از F1-Score به جای Accuracy
    * Precision-Recall Curve

سوال ۴: یافته‌های خود را مقایسه و گزارش کنید
پاسخ:
1. Random Forest vs XGBoost:
    * RF: پایدارتر، تفسیرپذیری بهتر
    * XGBoost: عملکرد بهتر، آموزش سریع‌تر
2. تعداد برگ‌ها:
    * ۳۰۰ برگ بهتر از ۱۰۰ برگ (پیچیدگی بیشتر = دقت بیشتر)
3. ویژگی‌ها:
    * تمام ویژگی‌ها: عملکرد کمی بهتر
    * ویژگی‌های منتخب: سریع‌تر، تفاوت عملکرد ناچیز
4. عملکرد نهایی:
    * بهترین مدل: XGBoost با تمام ویژگی‌ها
    * دقت: حدود ۸۹%
    * F1-Score: حدود ۸۴%

سوال ۵: چطور پیش‌بینی‌های مدل را برای پزشکان قابل درک می‌کنید؟
پاسخ:
1. اهمیت ویژگی‌ها: به پزشک نشان دهیم کدام فاکتورها بیشترین تاثیر را داشتند
2. نمره ریسک: تبدیل خروجی مدل به یک نمره ۰-۱۰۰
3. قوانین if-then:
    * "اگر بیمار بیش از ۵ روز بستری بود و بیش از ۱۰ دارو مصرف کرد → ریسک بالا"
4. شواهد contradict: اگر برخی فاکتورها با پیش‌بینی مخالف بودند، نشان دهیم
5. داشبورد ساده: یک رابط کاربری ساده برای پزشکان

نتیجه نهایی: سیستم ما با دقت قابل قبولی می‌تواند بیماران پرریسک را شناسایی کند، اما باید توجه کنیم:
* داده‌های نامتوازن را مدیریت کنیم
* بایاس مدل را بررسی کنیم
* نتایج را به صورت قابل درک برای پزشکان ارائه دهیم
















