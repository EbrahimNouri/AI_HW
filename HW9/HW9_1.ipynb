{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "f8d60825b38bdd96",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 17,
   "source": [
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "x = np.random.uniform(0, 2*np.pi, n)\n",
    "\n",
    "x1 = x**3\n",
    "x2 = np.sin(x)\n",
    "\n",
    "mu = 1\n",
    "sigma2 = 0.2\n",
    "noise = np.random.normal(mu, np.sqrt(sigma2), n)\n",
    "\n",
    "y = 2 - x1 + 3*x2 + noise\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    ndei = rmse / np.std(y_true)\n",
    "    return mse, rmse, ndei"
   ],
   "id": "a24b5487b21f3063"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:52:46.613839Z",
     "start_time": "2025-12-26T06:52:46.604057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model 1: feature = x^2 , b = 2 (fixed)\n",
    "X = x**2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# without normalization\n",
    "y_train_adj = y_train - 2\n",
    "w_hat = np.sum(X_train * y_train_adj) / np.sum(X_train**2)\n",
    "\n",
    "y_pred_train = 2 + w_hat * X_train\n",
    "y_pred_test = 2 + w_hat * X_test\n",
    "\n",
    "m1_train = regression_metrics(y_train, y_pred_train)\n",
    "m1_test = regression_metrics(y_test, y_pred_test)\n",
    "print(\"m1_train: Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m1_train))\n",
    "print(\"m1_test:  Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m1_test))\n"
   ],
   "id": "94d4bf10ff66757b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1_train: Total Error = 263.50, RMSE = 16.23, R2 = 0.224\n",
      "m1_test:  Total Error = 258.30, RMSE = 16.07, R2 = 0.237\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:52:46.625127Z",
     "start_time": "2025-12-26T06:52:46.619570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_n = scaler.fit_transform(X_train.reshape(-1,1)).flatten()\n",
    "X_test_n = scaler.transform(X_test.reshape(-1,1)).flatten()\n",
    "\n",
    "y_train_adj = y_train - 2\n",
    "w_hat_n = np.sum(X_train_n * y_train_adj) / np.sum(X_train_n**2)\n",
    "\n",
    "y_pred_train_n = 2 + w_hat_n * X_train_n\n",
    "y_pred_test_n = 2 + w_hat_n * X_test_n\n",
    "\n",
    "m1_train_n = regression_metrics(y_train, y_pred_train_n)\n",
    "m1_test_n = regression_metrics(y_test, y_pred_test_n)\n",
    "print(\"m1_train: Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m1_train_n))\n",
    "print(\"m1_test:  Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m1_test_n))\n"
   ],
   "id": "aafc305259b5973c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1_train: Total Error = 3816.77, RMSE = 61.78, R2 = 0.851\n",
      "m1_test:  Total Error = 3783.53, RMSE = 61.51, R2 = 0.906\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:52:46.636366Z",
     "start_time": "2025-12-26T06:52:46.630653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model 2: x1 & x2 , NO bias\n",
    "X12 = np.column_stack((x1, x2))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X12, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lr_no_bias = LinearRegression(fit_intercept=False)\n",
    "lr_no_bias.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = lr_no_bias.predict(X_train)\n",
    "y_pred_test = lr_no_bias.predict(X_test)\n",
    "\n",
    "m2_train = regression_metrics(y_train, y_pred_train)\n",
    "m2_test = regression_metrics(y_test, y_pred_test)\n",
    "\n",
    "print(\"m1_train: Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m2_train))\n",
    "print(\"m1_test:  Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m2_test))\n"
   ],
   "id": "cb22f9542ce2594d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1_train: Total Error = 4.06, RMSE = 2.02, R2 = 0.028\n",
      "m1_test:  Total Error = 4.22, RMSE = 2.06, R2 = 0.030\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:52:46.648459Z",
     "start_time": "2025-12-26T06:52:46.642958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model 3: x1 & x2 WITH bias\n",
    "lr_bias = LinearRegression(fit_intercept=True)\n",
    "lr_bias.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = lr_bias.predict(X_train)\n",
    "y_pred_test = lr_bias.predict(X_test)\n",
    "\n",
    "m3_train = regression_metrics(y_train, y_pred_train)\n",
    "m3_test = regression_metrics(y_test, y_pred_test)\n",
    "\n",
    "print(\"m3_train: Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m3_train))\n",
    "print(\"m3_test:  Total Error = {:.2f}, RMSE = {:.2f}, R2 = {:.3f}\".format(*m3_test))"
   ],
   "id": "b45f88848bde5e84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m3_train: Total Error = 0.20, RMSE = 0.45, R2 = 0.006\n",
      "m3_test:  Total Error = 0.17, RMSE = 0.41, R2 = 0.006\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:52:46.664410Z",
     "start_time": "2025-12-26T06:52:46.653256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Effect of noise parameters\n",
    "def noise_experiment(mu, sigma2):\n",
    "    noise = np.random.normal(mu, np.sqrt(sigma2), n)\n",
    "    y_new = 2 - x1 + 3*x2 + noise\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X12, y_new, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred = model.predict(X_te)\n",
    "    return regression_metrics(y_te, y_pred)\n",
    "\n",
    "noise_results = {\n",
    "    \"low_noise\": noise_experiment(0, 0.05),\n",
    "    \"base_noise\": noise_experiment(1, 0.2),\n",
    "    \"high_noise\": noise_experiment(2, 0.5)\n",
    "}\n",
    "\n",
    "\n",
    "for key, (total_error, rmse, r2) in noise_results.items():\n",
    "    print(f\"{key}: Total Error = {total_error:.3f}, RMSE = {rmse:.3f}, R² = {r2:.3f}\")\n"
   ],
   "id": "ae9d14643e07d09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low_noise: Total Error = 0.043, RMSE = 0.207, R² = 0.003\n",
      "base_noise: Total Error = 0.212, RMSE = 0.461, R² = 0.007\n",
      "high_noise: Total Error = 0.442, RMSE = 0.665, R² = 0.010\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:52:46.679203Z",
     "start_time": "2025-12-26T06:52:46.671351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_design = np.column_stack([np.ones(len(X_train)), X_train])\n",
    "X_T = X_design.T  # Xᵀ\n",
    "X_T_X = X_T @ X_design  # XᵀX\n",
    "X_T_X_inv = np.linalg.inv(X_T_X)  # (XᵀX)⁻¹\n",
    "X_T_y = X_T @ y_train  # XᵀY\n",
    "\n",
    "theta_matrix = X_T_X_inv @ X_T_y  # θ = (XᵀX)⁻¹ XᵀY\n",
    "\n",
    "def calculate_ndel(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    std_y = np.std(y_true)\n",
    "    ndel = rmse / std_y\n",
    "    return ndel\n",
    "\n",
    "y_pred_matrix_train = X_design @ theta_matrix\n",
    "y_pred_matrix_test = np.column_stack([np.ones(len(X_test)), X_test]) @ theta_matrix\n",
    "\n",
    "ndel_train_matrix = calculate_ndel(y_train, y_pred_matrix_train)\n",
    "ndel_test_matrix = calculate_ndel(y_test, y_pred_matrix_test)\n",
    "\n",
    "print(f\"NDEL on train: {ndel_train_matrix:.4f}\")\n",
    "print(f\"NDEL on test: {ndel_test_matrix:.4f}\")\n",
    "\n",
    "ndel_train_sklearn = calculate_ndel(y_train, y_pred_train)\n",
    "ndel_test_sklearn = calculate_ndel(y_test, y_pred_test)\n",
    "\n",
    "print(f\"NDEL on train: {ndel_train_sklearn:.4f}\")\n",
    "print(f\"NDEL on test: {ndel_test_sklearn:.4f}\")\n"
   ],
   "id": "564eee91944556dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDEL on train: 0.0062\n",
      "NDEL on test: 0.0061\n",
      "NDEL on train: 0.0062\n",
      "NDEL on test: 0.0061\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1️⃣ Bias کم، خطا کم\n",
    "\n",
    "مدل ساده یا پیچیده ولی خوب fit کرده.\n",
    "\n",
    "هم روی train و هم روی test خطا کم هست.\n",
    "\n",
    "وضعیت: مدل عالی، نه underfit و نه overfit.\n",
    "\n",
    "مثال: Linear Regression خوب روی داده‌های خطی.\n",
    "\n",
    "2️⃣ Bias کم، خطا زیاد\n",
    "\n",
    "مدل پیچیده که روی train خیلی خوبه ولی روی test ضعیفه.\n",
    "\n",
    "Overfitting: مدل جزئیات نویز train رو هم یاد گرفته.\n",
    "\n",
    "R² روی train بالا، روی test پایین.\n",
    "\n",
    "راه حل: Regularization (Ridge/Lasso)، کاهش پیچیدگی مدل، افزایش داده.\n",
    "\n",
    "3️⃣ Bias زیاد، خطا کم\n",
    "\n",
    "این حالت خیلی نادره، معمولاً وقتی داده‌ها خیلی نزدیک صفر یا بدون تغییر هستند اتفاق میفته.\n",
    "\n",
    "مدل ساده است، خطا عددی کم چون مقادیر هدف کوچک هستند، ولی مدل هیچ رابطه‌ای یاد نگرفته → R² پایین.\n",
    "\n",
    "مثال: مدل همیشه میانگین y رو پیش‌بینی می‌کنه.\n",
    "\n",
    "وضعیت: underfitting ولی خطا ظاهراً کم است.\n",
    "\n",
    "4️⃣ Bias زیاد، خطا زیاد\n",
    "\n",
    "مدل خیلی ساده و ضعیف برای داده‌های پیچیده.\n",
    "\n",
    "نه روی train و نه روی test خوب کار نمی‌کنه.\n",
    "\n",
    "Underfitting شدید: مدل نمی‌تونه رابطه‌ها رو یاد بگیره.\n",
    "\n",
    "مثال: Linear Regression ساده روی داده‌های غیرخطی شدید."
   ],
   "id": "f301f41f9ec13b95"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
